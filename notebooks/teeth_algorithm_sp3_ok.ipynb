{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算基於 ['enamel_x'] 和 ['enamel_y'] 的距離函數\n",
    "def calculate_distance(row_true, row_cleaned):\n",
    "    true_values = np.array([row_true['enamel_x'], row_true['enamel_y']])\n",
    "    cleaned_values = np.array([row_cleaned['enamel_x'], row_cleaned['enamel_y']])\n",
    "    return np.linalg.norm(true_values - cleaned_values)\n",
    "\n",
    "# 此函數使用影像的輪廓來計算物體的旋轉角度，確保物體的長邊垂直\n",
    "def get_rotation_angle(mask):\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(contours) == 0:\n",
    "        return 0\n",
    "    cnt = contours[0]\n",
    "\n",
    "    # Get rotated rectangle from the largest contour\n",
    "    rect = cv2.minAreaRect(cnt)\n",
    "    angle = rect[2]\n",
    "\n",
    "    #print(angle)\n",
    "    # Ensure the longest side is vertical\n",
    "    if rect[1][0] > rect[1][1]:\n",
    "        angle += 90\n",
    "    if angle > 90:\n",
    "        angle += 180\n",
    "    return angle\n",
    "\n",
    "# 此函數根據給定的角度旋轉圖像，保持中心點不變。\n",
    "def rotate_image(image, angle):\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "\n",
    "    # Perform the rotation\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h))\n",
    "\n",
    "    return rotated\n",
    "\n",
    "# 此函數將旋轉後的座標轉換回旋轉前的原始座標。\n",
    "def convert_coord_back(coord, angle, image):\n",
    "    (h, w) = image.shape[:2]\n",
    "    (cX, cY) = (w // 2, h // 2)\n",
    "    \n",
    "    # Create the inverse rotation matrix\n",
    "    M_inv = cv2.getRotationMatrix2D((cX, cY), -angle, 1.0)\n",
    "    \n",
    "    # Add a one to the coordinate for matrix multiplication\n",
    "    coord_ones = np.array([coord[0], coord[1], 1.0])\n",
    "    \n",
    "    # Perform the inverse rotation\n",
    "    original_coord_back = M_inv.dot(coord_ones)\n",
    "    \n",
    "    original_coord_back = original_coord_back[:2].astype(int)\n",
    "    \n",
    "    return original_coord_back\n",
    "\n",
    "# 此函數判斷某個值是否位於目標範圍內\n",
    "def is_within_range(value, target, range_size=50):\n",
    "    return target - range_size <= value <= target + range_size\n",
    "\n",
    "# 負責當其中一側的 dentin 值為 None 時，自動分配另一側的值，以避免缺失資料\n",
    "def assign_non_none_values(dentin_left_x, dentin_left_y, dentin_right_x, dentin_right_y):\n",
    "    # 检查 dentin_left_x 和 dentin_right_x\n",
    "    if dentin_left_x is None and dentin_right_x is not None:\n",
    "        dentin_left_x = dentin_right_x\n",
    "    elif dentin_right_x is None and dentin_left_x is not None:\n",
    "        dentin_right_x = dentin_left_x\n",
    "\n",
    "    # 检查 dentin_left_y 和 dentin_right_y\n",
    "    if dentin_left_y is None and dentin_right_y is not None:\n",
    "        dentin_left_y = dentin_right_y\n",
    "    elif dentin_right_y is None and dentin_left_y is not None:\n",
    "        dentin_right_y = dentin_left_y\n",
    "\n",
    "    return dentin_left_x, dentin_left_y, dentin_right_x, dentin_right_y\n",
    "\n",
    "#　此函數從輪廓中選取根據 y 坐標排序的前 100 個點，用來定位牙齒或組織的特定區域\n",
    "def get_top_100_points(contours, reverse=True):\n",
    "    all_points = []\n",
    "    for contour in contours:\n",
    "        sorted_points = sorted(contour, key=lambda x: x[0][1], reverse=reverse)\n",
    "        top_points = sorted_points\n",
    "        all_points.extend(top_points)\n",
    "    # Sort all points and get the top 10\n",
    "    all_points = sorted(all_points, key=lambda x: x[0][1], reverse=reverse)\n",
    "    return all_points\n",
    "\n",
    "\n",
    "# 计算 true_stage\n",
    "def calculate_true_stage(row):\n",
    "    enamel_x, enamel_y = row['enamel_x'], row['enamel_y']\n",
    "    gum_x, gum_y = row['gum_x'], row['gum_y']\n",
    "    dentin_x, dentin_y = row['dentin_x'], row['dentin_y']\n",
    "    \n",
    "    # 计算 A, B, C 點之間的距離\n",
    "    AB = np.sqrt((enamel_x - gum_x) ** 2 + (enamel_y - gum_y) ** 2)\n",
    "    AC = np.sqrt((enamel_x - dentin_x) ** 2 + (enamel_y - dentin_y) ** 2)\n",
    "    \n",
    "    # 计算 percentage\n",
    "    percentage = (AB / AC) * 100\n",
    "    \n",
    "    # 判定 true_stage\n",
    "    if percentage < 15:\n",
    "        stage = \"I\"\n",
    "    elif 15 <= percentage <= 33:\n",
    "        stage = \"II\"\n",
    "    else:\n",
    "        stage = \"III\"\n",
    "    \n",
    "    return stage\n",
    "               \n",
    "# 計算 percentage 和期數\n",
    "def calculate_predicted_stage(row):\n",
    "    enamel_x, enamel_y = row['enamel_x'], row['enamel_y']\n",
    "    gum_x, gum_y = row['gum_x'], row['gum_y']\n",
    "    dentin_x, dentin_y = row['dentin_x'], row['dentin_y']\n",
    "    \n",
    "    # 計算 A, B, C 點之間的距離\n",
    "    AB = np.sqrt((enamel_x - gum_x) ** 2 + (enamel_y - gum_y) ** 2)\n",
    "    AC = np.sqrt((enamel_x - dentin_x) ** 2 + (enamel_y - dentin_y) ** 2)\n",
    "    \n",
    "    # 計算 percentage\n",
    "    percentage = (AB / AC) * 100\n",
    "    \n",
    "    # 判斷期數\n",
    "    if percentage < 15:\n",
    "        stage = \"I\"\n",
    "    elif 15 <= percentage <= 33:\n",
    "        stage = \"II\"\n",
    "    else:\n",
    "        stage = \"III\"\n",
    "    \n",
    "    return percentage, stage   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def split_erase():\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "Match_Shift = 10\n",
    "Side_Contou_THD = 150\n",
    "Match_Dist = 50\n",
    "Window_Group = 100\n",
    "Slide_Group = 4\n",
    "\n",
    "def get_end_point(mask_sobj_in, flag_dir = 0):\n",
    "    \n",
    "    y_arr, x_arr = np.nonzero(mask_sobj_in)\n",
    "    \n",
    "    sorted_indx = np.argsort(y_arr)\n",
    "    \n",
    "    if(flag_dir == 0):#Top\n",
    "        return x_arr[sorted_indx[-1]], y_arr[sorted_indx[-1]]\n",
    "        \n",
    "    else:#Bottom\n",
    "        return x_arr[sorted_indx[0]], y_arr[sorted_indx[0]]\n",
    "\n",
    "def group_intersec(mask_inter_in, mask_org):\n",
    "    \n",
    "    mask_inter_cp = np.copy(mask_inter_in)\n",
    "    group_inter = np.zeros_like(mask_inter_cp)\n",
    "    width = mask_inter_cp.shape[1]\n",
    "    \n",
    "    st_x = 0\n",
    "    ed_x = st_x + Window_Group\n",
    "    list_can_x = []\n",
    "    list_can_area = []\n",
    "    find_flag = 0\n",
    "    list_st = []\n",
    "    while (ed_x < width):\n",
    "        mk_win = mask_inter_cp[:, st_x:ed_x]\n",
    "        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mk_win, connectivity=8)\n",
    "        \n",
    "        print(num_labels)\n",
    "        \n",
    "        if num_labels <= 2:\n",
    "            if find_flag == 1:\n",
    "                find_flag = 0\n",
    "               \n",
    "                sort_indx = np.argsort(list_can_area)\n",
    "                list_st.append(list_can_x[sort_indx[-1]])\n",
    "                \n",
    "                list_can_x.clear()\n",
    "                list_can_area.clear()\n",
    "            \n",
    "            \n",
    "            st_x += Slide_Group\n",
    "            ed_x = st_x + Window_Group    \n",
    "                    \n",
    "            continue\n",
    "        \n",
    "        else:\n",
    "            find_flag = 1\n",
    "\n",
    "            tot_area = 0\n",
    "            for i in range(1, num_labels):\n",
    "                tot_area += stats[i, cv2.CC_STAT_AREA]        \n",
    "            list_can_area.append(tot_area)\n",
    "            list_can_x.append(st_x)\n",
    "\n",
    "            \n",
    "            st_x += Slide_Group\n",
    "            ed_x = st_x + Window_Group\n",
    "\n",
    "            print('find ' + str(st_x))\n",
    "        \n",
    "        \n",
    "    print(list_st)\n",
    "    \n",
    "    \n",
    "    \n",
    "    mask_divide = np.copy(mask_org)\n",
    "    \n",
    "    i = 0\n",
    "    while(i < len(list_st)):\n",
    "        st = list_st[i]\n",
    "        \n",
    "        mask_tmp = np.copy(mask_inter_in)\n",
    "        mask_tmp[:, 0:st] = 0\n",
    "        mask_tmp[:, st + Window_Group:] = 0\n",
    "        \n",
    "        coordinates = np.argwhere(mask_tmp == 255)\n",
    "        coord_list = [tuple(coord) for coord in coordinates]\n",
    "    \n",
    "        kmeans = KMeans(n_clusters=2, random_state=0, n_init=\"auto\").fit(coord_list)\n",
    "        \n",
    "        print(kmeans.cluster_centers_)\n",
    "        print(type(kmeans.cluster_centers_))\n",
    "        \n",
    "        start_point = (int(kmeans.cluster_centers_[0][1]), int(kmeans.cluster_centers_[0][0]))\n",
    "        end_point = (int(kmeans.cluster_centers_[1][1]), int(kmeans.cluster_centers_[1][0]))\n",
    "        \n",
    "        cv2.line(mask_divide, start_point, end_point, 0, 4)\n",
    "    \n",
    "        i += 1\n",
    "    \n",
    "    return mask_divide\n",
    "    \n",
    "    \n",
    "def mask_intersec(mask_lt_in, mask_rt_in, rec_y, rec_h, comp_mask_in):\n",
    "    mk_lt = np.copy(mask_lt_in)\n",
    "    mk_rt = np.copy(mask_rt_in)\n",
    "    comp_mask = np.copy(comp_mask_in)\n",
    "    \n",
    "    # 使用 warpAffine 進行平移\n",
    "    height, width = mk_lt.shape[:2]\n",
    "    M = np.float32([[1, 0, Match_Shift], [0, 1, 0]])\n",
    "    mk_lt_sf = cv2.warpAffine(mk_lt, M, (width, height))\n",
    "    M = np.float32([[1, 0, -Match_Shift], [0, 1, 0]])\n",
    "    mk_rt_sf = cv2.warpAffine(mk_rt, M, (width, height))\n",
    "    \n",
    "    mask_inter = cv2.bitwise_and(mk_lt_sf, mk_rt_sf)\n",
    "    \n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask_inter, connectivity=8)\n",
    "    intersec_id = 1\n",
    "    for i in range(1, num_labels):\n",
    "        if centroids[i][1] < rec_y + 0.5*rec_h:\n",
    "                continue\n",
    "        \n",
    "    return mask_inter\n",
    "    \n",
    "def match_intersec_up(mask_lt_in, mask_rt_in, rec_y, rec_h, comp_mask_in):\n",
    "    label_intersec = np.zeros_like(mask_lt_in)\n",
    "    mk_lt = np.copy(mask_lt_in)\n",
    "    mk_rt = np.copy(mask_rt_in)\n",
    "    comp_mask = np.copy(comp_mask_in)\n",
    "    \n",
    "    # 使用 warpAffine 進行平移\n",
    "    height, width = mk_lt.shape[:2]\n",
    "    print(mk_lt.shape)\n",
    "    M = np.float32([[1, 0, 10], [0, 1, 0]])\n",
    "    mk_lt_sf = cv2.warpAffine(mk_lt, M, (width, height))\n",
    "    M = np.float32([[1, 0, -10], [0, 1, 0]])\n",
    "    mk_rt_sf = cv2.warpAffine(mk_rt, M, (width, height))\n",
    "    \n",
    "    label_intersec = cv2.bitwise_and(diff_mask1, diff_mask2)\n",
    "        \n",
    "    return label_intersec\n",
    "    \n",
    "def match_intersec_down(mask_lt_in, mask_rt_in, rec_y, rec_h, comp_mask):\n",
    "    label_intersec = np.zeros_like(mask_lt_in)\n",
    "    mk_lt = np.copy(mask_lt_in)\n",
    "    mk_rt = np.copy(mask_rt_in)\n",
    "    num_labels_lt, labels_lt, stats_lt, centroids_lt = cv2.connectedComponentsWithStats(mk_lt, connectivity=8)\n",
    "    num_labels_rt, labels_rt, stats_rt, centroids_rt = cv2.connectedComponentsWithStats(mk_rt, connectivity=8)\n",
    "    intersec_id = 1\n",
    "    for i in range(1, num_labels_lt):\n",
    "        if centroids_lt[i][1] < rec_y + 0.7*rec_h:\n",
    "            continue\n",
    "        \n",
    "        mask_sobj_lt = np.zeros_like(mask_lt_in)\n",
    "        mask_sobj_lt[labels_lt == i] = 255\n",
    "        x_lt, y_lt = get_end_point(mask_sobj_lt, 0)\n",
    "        \n",
    "        # print('x_lt shape={}'.format(x_lt.shape))\n",
    "        \n",
    "        for j in range(1, num_labels_rt):\n",
    "            if centroids_rt[j][1] < rec_y + 0.7*rec_h:\n",
    "                continue\n",
    "            mask_sobj_rt = np.zeros_like(mask_rt_in)\n",
    "            mask_sobj_rt[labels_rt == j] = 255\n",
    "            x_rt, y_rt = get_end_point(mask_sobj_rt, 0)\n",
    "            \n",
    "            dist = math.hypot(x_lt - x_rt, y_lt - y_rt)    \n",
    "            if(dist < Match_Dist):\n",
    "                label_intersec[(y_lt + y_rt) / 2][(x_lt + x_rt) / 2] = intersec_id\n",
    "                intersec_id += 1\n",
    "        \n",
    "    return label_intersec\n",
    "    \n",
    "    \n",
    "#Filter Noise Components\n",
    "def process_mask(mask_in):\n",
    "    mask = np.zeros_like(mask_in)\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask_in, connectivity=8)\n",
    "    for i in range(1, num_labels):\n",
    "        if stats[i, cv2.CC_STAT_AREA] > Side_Contou_THD :\n",
    "            mask[labels == i] = 255\n",
    "            print(stats[i, cv2.CC_STAT_AREA])\n",
    "\n",
    "    # cv2.imshow('img-mask-in2', mask)\n",
    "            \n",
    "    return mask\n",
    "            \n",
    "def enhance_split_detin(dentin_bin):\n",
    "    \n",
    "    num_labels, labels = cv2.connectedComponents(dentin_bin)\n",
    "\n",
    "    for i in range(1, num_labels):\n",
    "    \n",
    "        component_mask = np.uint8(labels == i) * 255\n",
    "        mask_rgb = cv2.cvtColor(component_mask, cv2.COLOR_GRAY2RGB)\n",
    "        \n",
    "        # 獲取圖像尺寸\n",
    "        height, width = component_mask.shape[:2]\n",
    "        # 定義平移矩陣\n",
    "        M = np.float32([[1, 0, 3], [0, 1, 0]])\n",
    "        # 使用 warpAffine 進行平移\n",
    "        shifted_mask = cv2.warpAffine(component_mask, M, (width, height))\n",
    "        diff_mask1 = np.int16(component_mask) - np.int16(shifted_mask)\n",
    "        diff_mask1[diff_mask1 < 0] = 0\n",
    "        diff_mask1 = np.uint8(diff_mask1)\n",
    "        diff_mask1 = process_mask(diff_mask1)\n",
    "        \n",
    "        M = np.float32([[1, 0, -3], [0, 1, 0]])\n",
    "        # 使用 warpAffine 進行平移\n",
    "        shifted_mask = cv2.warpAffine(component_mask, M, (width, height))\n",
    "        diff_mask2 = np.int16(component_mask) - np.int16(shifted_mask)\n",
    "        diff_mask2[diff_mask2 < 0] = 0\n",
    "        diff_mask2 = np.uint8(diff_mask2)\n",
    "        diff_mask2 = process_mask(diff_mask2)\n",
    "        \n",
    "#         M = np.float32([[1, 0, 7], [0, 1, 0]]) 2, M, (width, height))\n",
    "        kernel = np.ones((3, 3), np.uint8)\n",
    "        diff_mask1 = cv2.dilate(diff_mask1, kernel, iterations=2)\n",
    "        diff_mask2 = cv2.dilate(diff_mask2, kernel, iterations=2)\n",
    "\n",
    "        contours, _ = cv2.findContours(component_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contou = contours[0]\n",
    "        rec_x, rec_y, rec_w, rec_h = cv2.boundingRect(contou)\n",
    "        rect = cv2.minAreaRect(contou)\n",
    "        boxp = cv2.boxPoints(rect)\n",
    "        boxp = np.int0(boxp)\n",
    "        # print(boxp)\n",
    "        \n",
    "        cv2.drawContours(mask_rgb, [boxp], 0, (0,255,0), 3)\n",
    "        cv2.imshow('mask_rgb', mask_rgb)\n",
    "\n",
    "        \n",
    "        mask_inter = mask_intersec(diff_mask2, diff_mask1, rec_y, rec_h, component_mask)\n",
    "        \n",
    "#         label_intersec_up = match_intersec_up(diff_mask1, diff_mask2, rec_y, rec_h, component_mask)\n",
    "#         label_intersec_dn = match_intersec_down(diff_mask1, diff_mask2, rec_y, rec_h, component_mask)\n",
    "        \n",
    "#         label_intersec_up[label_intersec_up > 0] = 255\n",
    "#         label_intersec_dn[label_intersec_dn > 0] = 255\n",
    "        \n",
    "#         label_intersec = cv2.bitwise_or(label_intersec_up, label_intersec_dn)\n",
    "        \n",
    "        comb_mask_or = cv2.bitwise_or(diff_mask1, diff_mask2)\n",
    "#         comb_mask_and = cv2.bitwise_and(diff_mask1, diff_mask2)\n",
    "        \n",
    "        mask_divide = group_intersec(mask_inter, component_mask)\n",
    "    \n",
    "        cv2.imshow('img', component_mask)\n",
    "        cv2.imshow('img-diff1', diff_mask1)\n",
    "        cv2.imshow('img-diff2', diff_mask2)\n",
    "        cv2.imshow('img-comb-or', comb_mask_or)\n",
    "        cv2.imshow('mask-intersec', mask_inter)\n",
    "        \n",
    "        cv2.imshow('mask-divide', mask_divide)\n",
    "        \n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def enhance_split_detin2(dentin_bin):\n",
    "\n",
    "    num_labels, labels = cv2.connectedComponents(dentin_bin)\n",
    "\n",
    "    for i in range(1, num_labels):\n",
    "    \n",
    "        component_mask = np.uint8(labels == i) * 255\n",
    "        mask_rgb = cv2.cvtColor(component_mask, cv2.COLOR_GRAY2RGB)\n",
    "        \n",
    "        area = cv2.countNonZero(component_mask)\n",
    "        if area < 500:\n",
    "            #print(\"Skip, area = \" ,area)\n",
    "            continue\n",
    "        #print(area)\n",
    "        contours, _ = cv2.findContours(component_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        contou = contours[0]\n",
    "        print(\"there are \" + str(len(contou)) + \" points in contours[0]\")\n",
    "        hull = cv2.convexHull(contou, returnPoints = False)\n",
    "        defects = cv2.convexityDefects(contou, hull)\n",
    "        print(\"after convexHull, there are \" + str(len(hull)) + \" points\")\n",
    "        \n",
    "        # cv2.drawContours(mask_rgb, [hull], 0, (0,255,0),-1)\n",
    "        \n",
    "        for i in range(defects.shape[0]):\n",
    "            s, e, f, d = defects[i, 0]\n",
    "            if d > 100:\n",
    "                start = tuple(contou[s][0])\n",
    "                end = tuple(contou[e][0])\n",
    "                far = tuple(contou[f][0])\n",
    "                cv2.line(mask_rgb, start, end, [0, 255, 0], 2)\n",
    "                cv2.circle(mask_rgb, start, 5, [0, 0, 255], -1)\n",
    "                cv2.circle(mask_rgb, end, 5, [0, 0, 255], -1)\n",
    "\n",
    "        cv2.imshow('im', mask_rgb)\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    dir_input = './teeth3/1_ovlp' # 原始資料夾路徑\n",
    "    \n",
    "    dir_list = os.listdir(dir_input)\n",
    "    \n",
    "    all_true_stages = []\n",
    "    all_predicted_stages = []\n",
    "    \n",
    "    for target_dir in dir_list:\n",
    "        predictions = []\n",
    "        dir_path = os.path.join(dir_input, target_dir)\n",
    "        if not os.path.isdir(dir_path):\n",
    "            continue\n",
    "        # 定義Mask圖片和原始圖片的path\n",
    "        gum_mask_path = os.path.join(dir_path, f\"gum_{target_dir}.png\")\n",
    "        teeth_mask_path = os.path.join(dir_path, f\"teeth_{target_dir}.png\")\n",
    "        dental_crown_path = os.path.join(dir_path, f\"dentalcrown_{target_dir}.png\")\n",
    "        crown_path = os.path.join(dir_path, f\"crown_{target_dir}.png\")\n",
    "        dentin_path = os.path.join(dir_path, f\"dentin_{target_dir}.png\")\n",
    "        original_img_path = os.path.join(dir_path, f\"raw_{target_dir}.png\")\n",
    "        correct_df = pd.read_excel(os.path.join(dir_path, f\"analysis_{target_dir}.xlsx\"))\n",
    "        print(f\"Processing {original_img_path} ...\")\n",
    "\n",
    "        # Load the images\n",
    "        gum_img = cv2.imread(gum_mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        teeth_img = cv2.imread(teeth_mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        dental_crown_img = cv2.imread(dental_crown_path, cv2.IMREAD_GRAYSCALE)\n",
    "        dentin_img = cv2.imread(dentin_path, cv2.IMREAD_GRAYSCALE)\n",
    "        crown_img = cv2.imread(crown_path, cv2.IMREAD_GRAYSCALE)\n",
    "        original_img = cv2.imread(original_img_path)\n",
    "\n",
    "        cv2.imshow('Detin Mask', dentin_img)\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "        # Threshold the images to binary\n",
    "        _, gum_bin = cv2.threshold(gum_img, 128, 255, cv2.THRESH_BINARY)\n",
    "        _, teeth_bin = cv2.threshold(teeth_img, 128, 255, cv2.THRESH_BINARY)\n",
    "        _, dental_crown_bin = cv2.threshold(dental_crown_img, 128, 255, cv2.THRESH_BINARY)\n",
    "        _, dentin_bin = cv2.threshold(dentin_img, 128, 255, cv2.THRESH_BINARY)\n",
    "        _, crown_bin = cv2.threshold(crown_img, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # 在Mask的圖片中找到輪廓\n",
    "        contours_gum, _ = cv2.findContours(gum_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours_teeth, _ = cv2.findContours(teeth_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours_dental_crown, _ = cv2.findContours(dental_crown_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours_dentin, _ = cv2.findContours(dentin_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # 複製原始圖片以進行標註\n",
    "        image = original_img.copy()\n",
    "        line_image = image.copy()\n",
    "\n",
    "        # 定義膨脹內核\n",
    "        kernel = np.ones((3, 3), np.uint8)\n",
    "\n",
    "        # 獲取圖像尺寸\n",
    "        height, width = dental_crown_bin.shape\n",
    "\n",
    "        # 為未遮罩的區域創建遮罩\n",
    "        non_masked_area = np.ones((height, width), dtype=np.uint8) * 255\n",
    "        \n",
    "        # 對牙冠Mask執行形態學操作\n",
    "        dental_crown_bin = cv2.erode(dental_crown_bin, kernel, iterations=5)\n",
    "        dental_crown_bin = cv2.dilate(dental_crown_bin, kernel, iterations=5)\n",
    "        \n",
    "        # 在牙冠Mask中找到連接的Components\n",
    "        num_labels, labels = cv2.connectedComponents(dental_crown_bin)\n",
    "        # 創建一個陣列來計算每個標籤的像素數\n",
    "        label_counts = np.bincount(labels.flatten())\n",
    "\n",
    "        # 設定閾值，僅保留像素數大於該值的區域\n",
    "        pixel_threshold = 2000  # 可根據需求調整閾值\n",
    "\n",
    "        # 創建一個新的二值圖像\n",
    "        filtered_image = np.zeros_like(gum_bin)\n",
    "\n",
    "        # 保留像素數大於閾值的區域\n",
    "        for label in range(1, num_labels):\n",
    "            print(label_counts[label])\n",
    "            if label_counts[label] > pixel_threshold:\n",
    "                filtered_image[labels == label] = 255\n",
    "\n",
    "        dental_crown_bin = filtered_image\n",
    "        n_kernel = np.ones((30, 1), np.uint8)\n",
    "\n",
    "        # 處理 dentin_bin 雜點\n",
    "        dentin_bin = cv2.erode(dentin_bin, n_kernel, iterations=1)\n",
    "        dentin_bin = cv2.dilate(dentin_bin, n_kernel, iterations=1)\n",
    "        gum_bin = cv2.dilate(gum_bin, n_kernel, iterations=2)\n",
    "        gum_bin = cv2.erode(gum_bin, n_kernel, iterations=2)\n",
    "        num_labels, labels = cv2.connectedComponents(gum_bin)\n",
    "\n",
    "        # 創建一個陣列來計算每個標籤的像素數\n",
    "        label_counts = np.bincount(labels.flatten())\n",
    "\n",
    "        # 找出最大區域的標籤 (忽略背景標籤 0)\n",
    "        max_label = np.argmax(label_counts[1:]) + 1\n",
    "\n",
    "        # 創建一個新的二值圖像，只保留最大區域\n",
    "        largest_component = np.zeros_like(gum_bin)\n",
    "        largest_component[labels == max_label] = 255\n",
    "        gum_bin = largest_component\n",
    "        \n",
    "        # 膨脹 gum\n",
    "        dilated_gum_bin = cv2.dilate(gum_bin, kernel, iterations=10)\n",
    "        num_labels, labels = cv2.connectedComponents(gum_bin)\n",
    "        # 創建一個陣列來計算每個標籤的像素數\n",
    "        label_counts = np.bincount(labels.flatten())\n",
    "\n",
    "        # 找出最大區域的標籤 (忽略背景標籤 0)\n",
    "        max_label = np.argmax(label_counts[1:]) + 1\n",
    "\n",
    "        # 創建一個新的二值圖像，只保留最大區域\n",
    "        largest_component = np.zeros_like(gum_bin)\n",
    "        largest_component[labels == max_label] = 255\n",
    "        gum_bin = largest_component\n",
    "        \n",
    "        # Combine all masks using bitwise operations\n",
    "        combined_mask = cv2.bitwise_or(dilated_gum_bin, teeth_bin)\n",
    "        combined_mask = cv2.bitwise_or(combined_mask, dental_crown_bin)\n",
    "        combined_mask = cv2.bitwise_or(combined_mask, dentin_bin)\n",
    "\n",
    "        # Invert the combined mask to get the non-masked areas\n",
    "        non_masked_area = cv2.bitwise_not(combined_mask)\n",
    "        # 膨脹 mask\n",
    "        dilated_non_masked_area = cv2.dilate(non_masked_area, kernel, iterations=10)\n",
    "\n",
    "        enhance_split_detin(dentin_bin)\n",
    "        \n",
    "        # 獲取連通區域\n",
    "        num_labels, labels = cv2.connectedComponents(dentin_bin)\n",
    "\n",
    "        # 將 mask 以帶有透明度的方式疊加在原始圖像上\n",
    "        overlay = image.copy()\n",
    "        overlay[dental_crown_bin > 0] = (163, 118, 158)  # 將 dental_crown 顯示\n",
    "        overlay[dentin_bin > 0] = (117, 122, 152)  # 將 dentin 顯示\n",
    "        overlay[gum_bin > 0] = (0, 177, 177)  # 將 dentin 顯示\n",
    "        overlay[crown_bin > 0] = (255, 0, 128)# 將 crown 顯示\n",
    "\n",
    "\n",
    "        # 為每個區域創建一個獨立的 mask，進行膨脹並標註最左及最右交點\n",
    "        for i in range(1, num_labels):  # 從1開始，0是背景\n",
    "\n",
    "            component_mask = np.uint8(labels == i) * 255\n",
    "            \n",
    "            area = cv2.countNonZero(component_mask)\n",
    "            if area < 500:\n",
    "                #print(\"Skip, area = \" ,area)\n",
    "                continue\n",
    "            #print(area)\n",
    "            contours, _ = cv2.findContours(component_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            rect = cv2.minAreaRect(contours[0])\n",
    "            box = cv2.boxPoints(rect)\n",
    "            box = np.int64(box)\n",
    "            \n",
    "            \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./teeth3/1_ovlp\\13\\raw_13.png ...\n",
      "70013\n",
      "1481\n",
      "6328\n",
      "1662\n",
      "231\n",
      "399\n",
      "282\n",
      "438\n",
      "174\n",
      "492\n",
      "1416\n",
      "498\n",
      "306\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "find 944\n",
      "3\n",
      "find 948\n",
      "3\n",
      "find 952\n",
      "3\n",
      "find 956\n",
      "3\n",
      "find 960\n",
      "3\n",
      "find 964\n",
      "3\n",
      "find 968\n",
      "3\n",
      "find 972\n",
      "3\n",
      "find 976\n",
      "3\n",
      "find 980\n",
      "3\n",
      "find 984\n",
      "3\n",
      "find 988\n",
      "3\n",
      "find 992\n",
      "3\n",
      "find 996\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "[984]\n",
      "[[ 681.736       989.544     ]\n",
      " [ 327.15151515 1039.8989899 ]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\Anaconda3\\envs\\tf2-6_cv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "561\n",
      "486\n",
      "174\n",
      "486\n",
      "621\n",
      "543\n",
      "336\n",
      "414\n",
      "177\n",
      "417\n",
      "1296\n",
      "444\n",
      "549\n",
      "312\n",
      "186\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "find 176\n",
      "3\n",
      "find 180\n",
      "3\n",
      "find 184\n",
      "3\n",
      "find 188\n",
      "3\n",
      "find 192\n",
      "3\n",
      "find 196\n",
      "3\n",
      "find 200\n",
      "3\n",
      "find 204\n",
      "3\n",
      "find 208\n",
      "3\n",
      "find 212\n",
      "3\n",
      "find 216\n",
      "3\n",
      "find 220\n",
      "3\n",
      "find 224\n",
      "3\n",
      "find 228\n",
      "3\n",
      "find 232\n",
      "3\n",
      "find 236\n",
      "3\n",
      "find 240\n",
      "3\n",
      "find 244\n",
      "3\n",
      "find 248\n",
      "3\n",
      "find 252\n",
      "3\n",
      "find 256\n",
      "3\n",
      "find 260\n",
      "3\n",
      "find 264\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "find 388\n",
      "3\n",
      "find 392\n",
      "3\n",
      "find 396\n",
      "3\n",
      "find 400\n",
      "3\n",
      "find 404\n",
      "3\n",
      "find 408\n",
      "3\n",
      "find 412\n",
      "3\n",
      "find 416\n",
      "3\n",
      "find 420\n",
      "3\n",
      "find 424\n",
      "3\n",
      "find 428\n",
      "3\n",
      "find 432\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[216, 420]\n",
      "[[477.02083333 259.09722222]\n",
      " [603.52542373 271.47457627]]\n",
      "<class 'numpy.ndarray'>\n",
      "[[592.21800948 487.48815166]\n",
      " [364.31147541 426.04918033]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\Anaconda3\\envs\\tf2-6_cv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "E:\\ProgramData\\Anaconda3\\envs\\tf2-6_cv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
